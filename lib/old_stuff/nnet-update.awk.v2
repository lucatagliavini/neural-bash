BEGIN {
    if (debug) print "# Starting nnet-update.awk" > "/dev/stderr"

    read_weights(weights_file)
    read_inputs(input_file)
    read_gradients(grad_file)
    update_weights()
    write_weights(output_file)

    if (debug) print "# Update completed." > "/dev/stderr"
    exit
}

function read_weights(file,    i, j, tokens, line) {
    if (debug) print "# Reading weights from", file > "/dev/stderr"
    W_count = 0
    while ((getline line < file) > 0) {
        if (line ~ /^ACTIVATION=/) {
            activation_function = substr(line, index(line, "=") + 1)
            continue
        }
        if (line ~ /^ROWS=/) {
            nrows = int(substr(line, index(line, "=") + 1))
            continue
        }
        if (line ~ /^COLS=/) {
            ncols = int(substr(line, index(line, "=") + 1))
            continue
        }
        split(line, tokens, /[ \t]+/)
        for (i = 1; i <= length(tokens); i++) {
            W[W_count + 1, i] = tokens[i]
        }
        W_count++
    }
    close(file)
    if (debug) print "# Weights loaded: " nrows "x" ncols > "/dev/stderr"
}

function read_inputs(file,    i, j, tokens, line) {
    if (debug) print "# Reading inputs from", file > "/dev/stderr"
    input_rows = 0
    while ((getline line < file) > 0) {
        split(line, tokens, /[ \t]+/)
        for (i = 1; i <= length(tokens); i++) {
            X[input_rows + 1, i] = tokens[i]
        }
        input_rows++
    }
    close(file)
    if (debug) print "# Input examples:", input_rows > "/dev/stderr"
}

function read_gradients(file,    i, j, tokens, line) {
    if (debug) print "# Reading gradients from", file > "/dev/stderr"
    grad_rows = 0
    while ((getline line < file) > 0) {
        split(line, tokens, /[ \t]+/)
        for (j = 1; j <= length(tokens); j++) {
            D[grad_rows + 1, j] = tokens[j]
        }
        grad_rows++
    }
    close(file)
    if (debug) print "# Gradient rows:", grad_rows > "/dev/stderr"
}

function update_weights(   i, j, k, grad, val, update) {
    if (debug) print "# Updating weights..." > "/dev/stderr"
    for (j = 1; j <= nrows; j++) {
        for (i = 1; i <= ncols; i++) {
            update = 0
            for (k = 1; k <= grad_rows; k++) {
                grad = D[k, j]
                val = X[k, i]
                update += grad * val
            }
            update /= grad_rows  # media sul batch
            delta = learning_rate * update
            old_w = W[j, i]
            W[j, i] = old_w - delta
            if (debug) {
                printf "# neuron=%d i=%d old=%.6f update=%.6f new=%.6f\n", j, i, old_w, delta, W[j,i] > "/dev/stderr"
            }
        }
    }
}

function write_weights(file, i, j, line) {
    if (debug) print "# Writing updated weights to", file > "/dev/stderr"
    print "ACTIVATION=" activation_function > file
    print "ROWS=" nrows >> file
    print "COLS=" ncols >> file
    for (j = 1; j <= nrows; j++) {
        line = ""
        for (i = 1; i <= ncols; i++) {
            line = line sprintf("%.6f ", W[j,i])
        }
        print substr(line, 1, length(line)-1) >> file
    }
    close(file)
}


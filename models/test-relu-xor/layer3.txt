ACTIVATION=relu
0.610888 -0.453541 -0.360856 -1.130721 -0.011063 0.735764 -0.133101 -0.305833 0.398726

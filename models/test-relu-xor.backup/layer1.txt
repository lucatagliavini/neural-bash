ACTIVATION=relu
1.518797 2.923272 4.273673
-0.001095 -1.593558 -0.618731
2.307175 3.465140 3.840199
0.226745 0.154907 -1.304048
0.040568 0.367960 -0.629157
-1.095015 0.372446 -1.246665
-1.437274 -5.190229 -0.986851
0.047845 -2.106281 -4.087386
